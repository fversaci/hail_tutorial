{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6252f42-364b-45c7-ad3d-b9cc72873f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import datetime\n",
    "import hail as hl\n",
    "\n",
    "from hail.plot import show\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "hl.plot.output_notebook()\n",
    "\n",
    "from pyspark.conf import SparkConf\n",
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql.session import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14968cf1-19cb-474d-a0fc-183410ef88d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: set external ip\n",
    "import socket\n",
    "\n",
    "hostname = socket.gethostname()\n",
    "print(f\"hostname: {hostname}\")\n",
    "internal_ip = socket.gethostbyname(hostname)\n",
    "external_ip = \"172.19.179.46\"\n",
    "print(f\"internal ip: {internal_ip}\")\n",
    "print(f\"external ip: {external_ip}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52d3329-c2f0-4a48-ac25-c5341d9b6e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "HAIL_JARS = hl.__path__[0]\n",
    "HAIL_JARS += \"/backend/hail-all-spark.jar\"\n",
    "HAIL_JARS += \",/spark/jars/aws-java-sdk-bundle-1.11.1026.jar\"\n",
    "HAIL_JARS += \",/spark/jars/hadoop-aws-3.3.2.jar\"\n",
    "print(HAIL_JARS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6679e50f-9502-453d-85ba-3b38bbae1e3a",
   "metadata": {},
   "source": [
    "#### Start an [Apache Spark](https://en.wikipedia.org/wiki/Apache_Spark) instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ebe51c-4ab9-451e-a32f-226e5e477c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_file_name = f\"logs/hail-{datetime.datetime.now():%Y-%m-%d-%H-%M-%S}.log\"\n",
    "# run spark\n",
    "spark_conf = SparkConf().setAppName(\"hail-test\").setMaster(\"spark://172.19.179.106:30077\")\n",
    "# hail\n",
    "spark_conf.set(\"spark.jars\", HAIL_JARS)\n",
    "spark_conf.set(\"spark.driver.host\", external_ip)\n",
    "spark_conf.set(\"spark.driver.bindAddress\", internal_ip)\n",
    "spark_conf.set(\"spark.driver.port\", 32123)\n",
    "spark_conf.set(\"spark.blockManager.port\", 32124)\n",
    "# s3\n",
    "spark_conf.set(\"spark.hadoop.fs.s3a.endpoint\", \"http://172.19.179.106:30900/\")\n",
    "spark_conf.set(\"spark.hadoop.fs.s3a.access.key\", \"root\")\n",
    "spark_conf.set(\"spark.hadoop.fs.s3a.secret.key\", \"passpass\" )\n",
    "spark_conf.set(\"spark.hadoop.fs.s3a.connection.ssl.enabled\", \"false\")\n",
    "spark_conf.set(\"spark.hadoop.fs.s3a.path.style.access\", \"true\")\n",
    "spark_conf.set(\"spark.hadoop.fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\")\n",
    "spark_conf.set(\"spark.hadoop.fs.s3a.connection.maximum\", 1024);\n",
    "spark_conf.set(\"spark.hadoop.fs.s3a.threads.max\", 1024);\n",
    "spark_conf.set(\"spark.hadoop.fs.s3.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\")\n",
    "# varia\n",
    "spark_conf.set(\"spark.executor.memory\", \"200g\")\n",
    "spark_conf.set(\"spark.driver.memory\", \"10g\")\n",
    "spark_conf.set(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\")\n",
    "spark_conf.set(\"spark.kryoserializer.buffer.max\", \"2047m\")\n",
    "spark_conf.set(\"spark.rpc.message.maxSize\", \"512\")\n",
    "spark_conf.set(\"spark.network.timeout\", \"600s\")\n",
    "spark_conf.set(\"spark.driver.maxResultSize\", \"4g\")\n",
    "spark_conf.set(\"spark.speculation\", \"true\")\n",
    "spark_conf.set(\"spark.speculation.quantile\", \"0.75\")\n",
    "spark_conf.set(\"spark.speculation.multiplier\", \"1.5\")\n",
    "\n",
    "try:\n",
    "    sc = SparkContext(conf=spark_conf)\n",
    "except:\n",
    "    print (\"Spark session already up\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e113ae2b-9754-4e8b-b2d3-2839ac142b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "hl.init(sc=sc, log=log_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44038d5-c712-4e6e-ba9f-03b3af0ca73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test hail\n",
    "mt = hl.balding_nichols_model(n_populations=3, n_samples=100, n_variants=1000)\n",
    "mt.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5ebad8-b211-480e-88a0-de4d5a560539",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read the matrix table from the file and assign it to the mt vaiable\n",
    "mt_fn=\"s3://lifemap/1kg_sparse.mt\"\n",
    "mt = hl.read_matrix_table(mt_fn)\n",
    "print(f\"partitions: {mt.n_partitions()}\")\n",
    "row_table = mt.rows()\n",
    "col_table = mt.cols()\n",
    "entry_fields = mt.entries()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57fcab9e-7302-49ee-962a-c58ca3d48054",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Summary of the matrix table:\n",
    "mt.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a5c7fd-1b4b-4281-a2a2-c7f5b7e8143d",
   "metadata": {},
   "source": [
    "#### Row table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ccae31-81b3-4dd4-afd8-de014d7a91aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "row_table.show(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
